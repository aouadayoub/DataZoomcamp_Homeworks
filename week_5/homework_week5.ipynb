{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cawXouwhDIQi",
        "outputId": "d5cb99dc-cb43-4734-d36e-9a809bd976fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.4)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "f0eFFprSDUl2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"TaxiDataProcessing\") \\\n",
        "    .config(\"spark.sql.catalogImplementation\", \"in-memory\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "6geLwCZNDVBv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(spark.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tezfz-UnDoK0",
        "outputId": "7febe499-f77c-4d1a-89eb-45ce12e58c30"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.5.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-10.parquet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fP5QZLH2D53L",
        "outputId": "c2b730ed-e5f5-4f21-eee4-d66da513b4fb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-02 00:10:03--  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-10.parquet\n",
            "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 18.154.99.47, 18.154.99.220, 18.154.99.225, ...\n",
            "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|18.154.99.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64346071 (61M) [binary/octet-stream]\n",
            "Saving to: ‘yellow_tripdata_2024-10.parquet’\n",
            "\n",
            "yellow_tripdata_202 100%[===================>]  61.36M   166MB/s    in 0.4s    \n",
            "\n",
            "2025-03-02 00:10:04 (166 MB/s) - ‘yellow_tripdata_2024-10.parquet’ saved [64346071/64346071]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.parquet(\"yellow_tripdata_2024-10.parquet\")"
      ],
      "metadata": {
        "id": "3YeUr2HMD8MG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_repartitioned = df.repartition(4)"
      ],
      "metadata": {
        "id": "O1LbvPyqEJAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NR0jf2WOJ8h9",
        "outputId": "8283cc4b-f688-45cb-f329-2f51ecc77904"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['VendorID',\n",
              " 'tpep_pickup_datetime',\n",
              " 'tpep_dropoff_datetime',\n",
              " 'passenger_count',\n",
              " 'trip_distance',\n",
              " 'RatecodeID',\n",
              " 'store_and_fwd_flag',\n",
              " 'PULocationID',\n",
              " 'DOLocationID',\n",
              " 'payment_type',\n",
              " 'fare_amount',\n",
              " 'extra',\n",
              " 'mta_tax',\n",
              " 'tip_amount',\n",
              " 'tolls_amount',\n",
              " 'improvement_surcharge',\n",
              " 'total_amount',\n",
              " 'congestion_surcharge',\n",
              " 'Airport_fee']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, to_date\n",
        "\n",
        "# Assuming the column with the trip start time is called 'tpep_pickup_datetime'\n",
        "# Convert tpep_pickup_datetime to a date format and filter for October 15th, 2024\n",
        "oct_15_trips = df.filter(to_date(col('tpep_pickup_datetime')) == '2024-10-15')\n",
        "\n",
        "# Count the number of records\n",
        "oct_15_count = oct_15_trips.count()\n",
        "\n",
        "print(f\"Number of taxi trips on 15th October 2024: {oct_15_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK4QuPWcELch",
        "outputId": "93beceac-bbea-4e91-e7d9-8690a62fd803"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of taxi trips on 15th October 2024: 128893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Calculate the duration in seconds\n",
        "df_with_duration = df.withColumn(\"trip_duration_seconds\",\n",
        "                                (F.unix_timestamp('tpep_dropoff_datetime') - F.unix_timestamp('tpep_pickup_datetime')))\n",
        "\n",
        "# Convert seconds to hours\n",
        "df_with_duration = df_with_duration.withColumn(\"trip_duration_hours\", df_with_duration[\"trip_duration_seconds\"] / 3600)\n",
        "\n",
        "# Find the maximum trip duration in hours\n",
        "max_trip_duration = df_with_duration.agg(F.max(\"trip_duration_hours\")).collect()[0][0]\n",
        "\n",
        "print(f\"The length of the longest trip in hours is: {max_trip_duration}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnlAxB7DLW-A",
        "outputId": "cabbaa17-8526-4812-a156-b4e81227e182"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of the longest trip in hours is: 162.61777777777777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfDmfubILja-",
        "outputId": "4fa07814-1b7b-4c44-eefd-18ae8658c7ea"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-02 00:11:09--  https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv\n",
            "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 54.230.209.140, 54.230.209.126, 54.230.209.72, ...\n",
            "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|54.230.209.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12331 (12K) [text/csv]\n",
            "Saving to: ‘taxi_zone_lookup.csv’\n",
            "\n",
            "\rtaxi_zone_lookup.cs   0%[                    ]       0  --.-KB/s               \rtaxi_zone_lookup.cs 100%[===================>]  12.04K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-02 00:11:09 (255 MB/s) - ‘taxi_zone_lookup.csv’ saved [12331/12331]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the zone lookup data into a Spark DataFrame\n",
        "zone_df = spark.read.option(\"header\", \"true\").csv(\"taxi_zone_lookup.csv\")\n",
        "\n",
        "# Create a temporary view for zone lookup\n",
        "zone_df.createOrReplaceTempView(\"zone_lookup\")"
      ],
      "metadata": {
        "id": "vc7D2YWhLk3K"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Join Yellow October 2024 DataFrame with the zone lookup DataFrame\n",
        "joined_df = df.join(zone_df, df.PULocationID == zone_df.LocationID, \"inner\")\n",
        "\n",
        "# Group by the zone name and count the frequency of each zone\n",
        "zone_counts = joined_df.groupBy(\"Zone\").count()\n",
        "\n",
        "# Find the zone with the least frequency (lowest count)\n",
        "least_frequent_zone = zone_counts.orderBy(\"count\").first()\n",
        "\n",
        "# Show the least frequent pickup location zone\n",
        "least_frequent_zone_name = least_frequent_zone[\"Zone\"]\n",
        "print(f\"The least frequent pickup location zone is: {least_frequent_zone_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "our91Vx8Lpct",
        "outputId": "a5db55d3-d81f-4b64-8b4d-2e846c3b1b55"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The least frequent pickup location zone is: Governor's Island/Ellis Island/Liberty Island\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Stop any existing Spark session\n",
        "SparkSession.builder.getOrCreate().stop()\n"
      ],
      "metadata": {
        "id": "1tSjCM6oFVj_"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}